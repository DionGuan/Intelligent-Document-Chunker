# ğŸ§© Intelligent Document Chunker

A lightweight knowledge base component for intelligent document segmentation using **semantic chunking techniques**.  
It supports both PDF and TXT inputs, performing structure-aware segmentation to enhance downstream knowledge retrieval and embedding quality.

---

## ğŸ“˜ Introduction

**Intelligent Document Chunker** is designed to automatically divide long-form documents (`.txt` or `.pdf`) into smaller, semantically meaningful chunks.  
It integrates robust text extraction (via `MinerU`) with semantic embedding models (`sentence-transformers`) to produce content-aware document partitions ideal for LLM preprocessing, vector database ingestion, or knowledge base construction.

---

## âœ¨ Features

- âœ… Supports both **TXT** and **PDF** input formats  
- ğŸ§  Performs **semantic segmentation** using `sentence-transformers`  
- ğŸ“„ Extracts and cleans text from PDFs using **MinerU** (or compatible tools)  
- ğŸ’¾ Exports chunked text as individual `.txt` files and a combined summary file  
- ğŸ“‚ Generates a structured output folder for easy downstream processing  

---

## âš™ï¸ Environment Requirements

- Python **3.8+**
- Recommended: Virtual environment for dependency isolation

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Clone or Download the Repository

```bash
git clone <your-repo-url>
# or simply download and extract the project archive

ğŸ’¡ Tip:
It is strongly recommended to create and activate a virtual environment before installation:
python -m venv .venv
.venv\Scripts\activate    # Windows
source .venv/bin/activate # macOS / Linux

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
# æ¨èä½¿ç”¨è™šæ‹Ÿç¯å¢ƒè¿›è¡Œéƒ¨ç½²ï¼Œä»¥éš”ç¦»ä¾èµ–

### 3ï¸âƒ£ Directory Structure
```bash
   Chunk/
   â”œâ”€â”€ main.py
   â”œâ”€â”€ semantic_chunker_local.py
   â”œâ”€â”€ document_loader_local.py
   â”œâ”€â”€ test_file.pdf # ç”¨ä»¥æµ‹è¯•çš„æ–‡ä»¶
   â””â”€â”€ output/ #ç”Ÿæˆçš„outputæ–‡ä»¶å¤¹
       â””â”€â”€ test_file/
           â”œâ”€â”€ test_file.chunk.1.txt
           â”œâ”€â”€ test_file.chunk.2.txt
           â”œâ”€â”€ ...
           â””â”€â”€ test_file.all_chunks.txt
           â””â”€â”€ auto/
               â”œâ”€â”€ test_file.md
               â”œâ”€â”€ test_file_content_list.json
               â”œâ”€â”€ test_file_layout.pdf
               â”œâ”€â”€ test_file_middle.json
               â”œâ”€â”€ test_file_model.json
               â”œâ”€â”€ test_file_origin.pdf
               â”œâ”€â”€ test_file_span.pdf
               â””â”€â”€ images/ #OCR æˆªå›¾
                   â”œâ”€â”€ img1.jpg
                   â”œâ”€â”€ img2.jpg
                   â””â”€â”€ ...

### 4ï¸âƒ£ Run the Program
   ```bash
   python main.py

You will be prompted to select a document (either `.txt` or `.pdf`).
The system will automatically process the file, perform semantic segmentation, and save the results in the output directory.

# ğŸ“œ License
æœ¬é¡¹ç›®ä»…ç”¨äºç ”ç©¶ä¸æ•™å­¦ç›®çš„ï¼Œå¯è‡ªç”±ä¿®æ”¹ã€å¤ç”¨ä¸æ‰©å±•ã€‚
