# semantic_chunker_local.py
# æ ‡å‡†çš„ LocalSemanticChunker ç±»å®šä¹‰
from langchain_experimental.text_splitter import SemanticChunker
from langchain_community.embeddings import HuggingFaceEmbeddings
from typing import List, Optional
import logging

logging.basicConfig(level=logging.INFO)

class LocalSemanticChunker:
    def __init__(
        self,
        embedding_model_name: str = "sentence-transformers/all-MiniLM-L6-v2", # @todo æ¢ qwen3-embedding
        # embedding_model_name: str = "qwen3-embedding",@Todo
        # embedding_model_kwargs: Optional[dict] = None,
        breakpoint_threshold_type: str = "percentile",
        breakpoint_threshold_amount: Optional[float] = 95,
        device: str = "cpu"
    ):
        self.embedding_model = HuggingFaceEmbeddings(
            model_name=embedding_model_name,
            model_kwargs={"device": device},
            encode_kwargs={"normalize_embeddings": True}
        )

        self.text_splitter = SemanticChunker(
            embeddings=self.embedding_model,
            breakpoint_threshold_type=breakpoint_threshold_type,
            breakpoint_threshold_amount=breakpoint_threshold_amount
        )

        logging.info(f"âœ… æœ¬åœ°è¯­ä¹‰åˆ‡åˆ†å™¨åŠ è½½å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {embedding_model_name}")

    def split_text(self, text: str) -> List[str]:
        if not text.strip():
            return []
        try:
            chunks = self.text_splitter.split_text(text)
            logging.info(f"ğŸ“„ æ–‡æœ¬åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªè¯­ä¹‰å—")
            return chunks
        except Exception as e:
            logging.error(f"âŒ æ–‡æœ¬åˆ‡åˆ†å¤±è´¥: {e}")
            raise # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…å¤„ç†
